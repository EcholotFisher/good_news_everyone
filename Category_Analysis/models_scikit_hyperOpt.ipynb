{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter optimization\n",
    "Use Grid search to find best parameters for models. Use full dataset to train final models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from plots_fabi import *\n",
    "import pickle\n",
    "import sys\n",
    "# Add functions path\n",
    "sys.path.append('../Functions')\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_stratified_dataset\n",
    "df = load_stratified_dataset(path='../Datasets/dataset_categories/dataset_categories_train.csv', labels='category', samples_per_label=1000, random_seed=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer generates bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# sublinear_tf: use logarithmic form for frequency\n",
    "# min_df: minimum numbers of documents a word must be present to keep it\n",
    "# ngram_range: number of ngrams to use\n",
    "# stopwords: remove all common pronouns in given language\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1',\n",
    "                        ngram_range=(1, 3), stop_words='english', max_features=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text_lem'], df['category'], random_state = 42)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# GridSearch\n",
    "Search for best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "'C': 5.994842503189409, 'multi_class': 'auto', 'penalty': 'l2'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "parameters = {'penalty': ['l1', 'l2', 'elasticnet'], 'C': np.logspace(-1,1,10), 'multi_class': ['auto', 'ovr', 'multinomial']}\n",
    "clf = GridSearchCV(LogisticRegression(max_iter = 10000, random_state=42), parameters, n_jobs=4, cv=5)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print(clf.score(X_train_tfidf, y_train), clf.score(X_test_tfidf, y_test))\n",
    "clf.best_params_\n",
    "\"\"\"\n",
    "print(\"'C': 5.994842503189409, 'multi_class': 'auto', 'penalty': 'l2'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "'C': 5.222222222222222, 'penalty': 'l2'\nResult: Train: 0.99, Test: 0.75\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "parameters = {'penalty': ['l2'], 'C': np.linspace(5, 7, 10)}\n",
    "clf = GridSearchCV(LogisticRegression(max_iter = 10000, random_state=42), parameters, n_jobs=4, cv=5)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print(clf.score(X_train_tfidf, y_train), clf.score(X_test_tfidf, y_test))\n",
    "clf.best_params_\n",
    "\"\"\"\n",
    "print(\"'C': 5.222222222222222, 'penalty': 'l2'\")\n",
    "print(\"Result: Train: 0.99, Test: 0.75\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "'C': 0.16681005372000587, 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l2'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "parameters = {'penalty': ['l1', 'l2'], 'C': np.logspace(-1,1,10), 'dual': [False, True], 'loss': ['hinge', 'squared_hinge']}\n",
    "clf = GridSearchCV(LinearSVC(max_iter = 10000, random_state=42), parameters, n_jobs=4, cv=5)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print(clf.score(X_train_tfidf, y_train), clf.score(X_test_tfidf, y_test))\n",
    "clf.best_params_\n",
    "\"\"\"\n",
    "print(\"'C': 0.16681005372000587, 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l2'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9167619047619048 0.7531428571428571\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'C': 0.17500000000000002,\n",
       " 'dual': False,\n",
       " 'loss': 'squared_hinge',\n",
       " 'penalty': 'l2'}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "parameters = {'penalty': ['l2'], 'C': np.linspace(0.1, 0.2, 5), 'dual': [False], 'loss': ['squared_hinge']}\n",
    "clf = GridSearchCV(LinearSVC(max_iter = 10000, random_state=42), parameters, n_jobs=4, cv=5)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print(clf.score(X_train_tfidf, y_train), clf.score(X_test_tfidf, y_test))\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 1000\nResult: Train: 0.99, Test: 0.71\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "parameters = {'n_estimators': [100, 400, 700, 1000], 'criterion': ['gini','entropy'], 'max_depth': [None, 10, 30, 50, 80], 'min_samples_split': [2, 6, 10, 15]}\n",
    "clf = GridSearchCV(RandomForestClassifier(random_state=42), parameters, n_jobs=4, cv=5)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print(clf.score(X_train_tfidf, y_train), clf.score(X_test_tfidf, y_test))\n",
    "clf.best_params_\n",
    "\"\"\"\n",
    "print(\"'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 1000\")\n",
    "print(\"Result: Train: 0.99, Test: 0.71\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 1300\nResult: Train: 0.99, Test: 0.71\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "parameters = {'n_estimators': [1000, 1300, 1500], 'criterion': ['gini'], 'max_depth': [None], 'min_samples_split': [2]}\n",
    "clf = GridSearchCV(RandomForestClassifier(random_state=42), parameters, n_jobs=4, cv=5)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print(clf.score(X_train_tfidf, y_train), clf.score(X_test_tfidf, y_test))\n",
    "clf.best_params_\n",
    "\"\"\"\n",
    "print(\"'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 1300\")\n",
    "print(\"Result: Train: 0.99, Test: 0.71\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "For __all models__ grid search does __not__ really seem to __improve__ accuracy. Probably since errors occur due to the dataset given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Full data optimization with balanced data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Smallest sample size in dataset is 12026 samples!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((84181, 8), (3500, 8))"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df_train = load_stratified_dataset(path='../Datasets/dataset_categories/dataset_categories_train.csv', labels='category', samples_per_label=99000, random_seed=42)\n",
    "df_test = pd.read_csv('../Datasets/dataset_categories/dataset_categories_test.csv')\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = df_train.text_lem\n",
    "X_test = df_test.text_lem\n",
    "y_train = df_train.category\n",
    "y_test = df_test.category\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training accuracy: 74.60%;  Test accuracy: 73.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "print('Training accuracy: {:.2f}%;  Test accuracy: {:.2f}%'.format(nb.score(X_train_tfidf, y_train)*100, nb.score(X_test_tfidf, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training accuracy: 91.91%;  Test accuracy: 80.97%\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=10000, random_state=42, C=5.2, multi_class= 'ovr', penalty='l2')\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "print('Training accuracy: {:.2f}%;  Test accuracy: {:.2f}%'.format(lr.score(X_train_tfidf, y_train)*100, lr.score(X_test_tfidf, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training accuracy: 87.31%;  Test accuracy: 80.23%\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(max_iter=10000, random_state=42, C=0.16, dual=False, loss='squared_hinge', penalty='l2')\n",
    "svc.fit(X_train_tfidf, y_train)\n",
    "print('Training accuracy: {:.2f}%;  Test accuracy: {:.2f}%'.format(svc.score(X_train_tfidf, y_train)*100, svc.score(X_test_tfidf, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train accuracy: 99.92%;  Test accuracy: 76.73%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "rf = RandomForestClassifier(random_state=42, criterion='gini', max_depth=None, min_samples_split=2, n_estimators= 1300)\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "print('Training accuracy: {:.2f}%;  Test accuracy: {:.2f}%'.format(rf.score(X_train_tfidf, y_train)*100, rf.score(X_test_tfidf, y_test)*100))\n",
    "\"\"\"\n",
    "print('Train accuracy: 99.92%;  Test accuracy: 76.73%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voter = VotingClassifier(estimators=[('lr', lr), ('svc', svc), ('nb', nb)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter.fit(X_train_tfidf, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training accuracy: 87.86%;  Test accuracy: 80.20%\n"
     ]
    }
   ],
   "source": [
    "print('Training accuracy: {:.2f}%;  Test accuracy: {:.2f}%'.format(voter.score(X_train_tfidf, y_train)*100, voter.score(X_test_tfidf, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Full data optimization with unbalanced data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((128873, 8), (3500, 8))"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "df_train = pd.read_csv('../Datasets/dataset_categories/dataset_categories_train.csv')\n",
    "df_test = pd.read_csv('../Datasets/dataset_categories/dataset_categories_test.csv')\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "technology       1.000000\n",
       "entertainment    1.000000\n",
       "world            1.000103\n",
       "travel           1.000205\n",
       "financial        1.000205\n",
       "sports           1.007076\n",
       "politics         1.621404\n",
       "Name: category, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# Sample weights for training\n",
    "cat_weight = 1/df_train.category.value_counts()*df_train.category.value_counts()[0]\n",
    "sample_weight = [cat_weight[i] for i in df_train.category]\n",
    "cat_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = df_train.text_lem\n",
    "y_train = df_train.category\n",
    "X_test = df_test.text_lem\n",
    "y_test = df_test.category\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training accuracy: 74.98%;  Test accuracy: 72.97%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tfidf, y_train, sample_weight=sample_weight)\n",
    "print('Training accuracy: {:.2f}%;  Test accuracy: {:.2f}%'.format(nb.score(X_train_tfidf, y_train)*100, nb.score(X_test_tfidf, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training accuracy: 91.44%;  Test accuracy: 81.60%\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=10000, random_state=42, C=5.2, multi_class= 'ovr', penalty='l2')\n",
    "lr.fit(X_train_tfidf, y_train, sample_weight=sample_weight)\n",
    "print('Training accuracy: {:.2f}%;  Test accuracy: {:.2f}%'.format(lr.score(X_train_tfidf, y_train)*100, lr.score(X_test_tfidf, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training accuracy: 87.60%;  Test accuracy: 81.11%\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(max_iter=10000, random_state=42, C=0.16, dual=False, loss='squared_hinge', penalty='l2')\n",
    "svc.fit(X_train_tfidf, y_train, sample_weight = sample_weight)\n",
    "print('Training accuracy: {:.2f}%;  Test accuracy: {:.2f}%'.format(svc.score(X_train_tfidf, y_train)*100, svc.score(X_test_tfidf, y_test)*100))"
   ]
  },
  {
   "source": [
    "***\n",
    "## Take full tfidf"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1',\n",
    "                        ngram_range=(1, 3), stop_words='english', max_features=None)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "source": [
    "#### Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training accuracy: 95.78%;  Test accuracy: 81.71%\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=10000, random_state=42, C=5.2, multi_class= 'ovr', penalty='l2')\n",
    "lr.fit(X_train_tfidf, y_train, sample_weight=sample_weight)\n",
    "print('Training accuracy: {:.2f}%;  Test accuracy: {:.2f}%'.format(lr.score(X_train_tfidf, y_train)*100, lr.score(X_test_tfidf, y_test)*100))"
   ]
  },
  {
   "source": [
    "#### Linear SVC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training accuracy: 96.44%;  Test accuracy: 82.37%\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(max_iter=10000, random_state=42, C=0.46, dual=False, loss='squared_hinge', penalty='l2')\n",
    "svc.fit(X_train_tfidf, y_train, sample_weight = sample_weight)\n",
    "print('Training accuracy: {:.2f}%;  Test accuracy: {:.2f}%'.format(svc.score(X_train_tfidf, y_train)*100, svc.score(X_test_tfidf, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LINSVC: Test accuracy: 82.37%\nLOGREG: Test accuracy: 81.71%\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('../Datasets/dataset_categories/dataset_categories_test.csv')\n",
    "X_test = df_test.text_lem\n",
    "y_test = df_test.category\n",
    "\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print('LINSVC: Test accuracy: {:.2f}%'.format(svc.score(X_test_tfidf, y_test)*100))\n",
    "print('LOGREG: Test accuracy: {:.2f}%'.format(lr.score(X_test_tfidf, y_test)*100))"
   ]
  },
  {
   "source": [
    "***\n",
    "## Save final model\n",
    "Save final model to use it on streamlit. Save the tfidf vectorizer and the svc model as pkl files. Write a class to load both models and use them to categorize final text.\n",
    "\n",
    "__Take smaller model__ since taking all features in only brings slight improvement."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1',\n",
    "                        ngram_range=(1, 3), stop_words='english', max_features=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# Observations in train set: 128873\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('../Datasets/dataset_categories/dataset_categories_train.csv')\n",
    "print('# Observations in train set: {}'.format(df_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.text_lem\n",
    "y_train = df_train.category\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "technology       1.000000\n",
       "entertainment    1.000000\n",
       "world            1.000103\n",
       "travel           1.000205\n",
       "financial        1.000205\n",
       "sports           1.007076\n",
       "politics         1.621404\n",
       "Name: category, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "# Sample weights for training\n",
    "cat_weight = 1/df_train.category.value_counts()*df_train.category.value_counts()[0]\n",
    "sample_weight = [cat_weight[i] for i in df_train.category]\n",
    "cat_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training accuracy: 91.44%\n"
     ]
    }
   ],
   "source": [
    "#svc = LinearSVC(max_iter=10000, random_state=42, C=0.16, dual=False, loss='squared_hinge', penalty='l2')\n",
    "#svc.fit(X_train_tfidf, y_train)\n",
    "#print('Training accuracy: {:.2f}%'.format(svc.score(X_train_tfidf, y_train)*100))\n",
    "lr = LogisticRegression(max_iter=10000, random_state=42, C=5.2, multi_class= 'ovr', penalty='l2')\n",
    "lr.fit(X_train_tfidf, y_train, sample_weight=sample_weight)\n",
    "print('Training accuracy: {:.2f}%'.format(lr.score(X_train_tfidf, y_train)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../Datasets/dataset_categories/dataset_categories_test.csv')\n",
    "X_test = df_test.text_lem\n",
    "y_test = df_test.category\n",
    "\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test accuracy: 81.60%\n"
     ]
    }
   ],
   "source": [
    "#print('Test accuracy: {:.2f}%'.format(svc.score(X_test_tfidf, y_test)*100))\n",
    "print('Test accuracy: {:.2f}%'.format(lr.score(X_test_tfidf, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete stop words to reduce size of file, they are not needed for prediction\n",
    "delattr(tfidf, 'stop_words_')\n",
    "clf = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tfidf, open(\"tfidf_categorizer.pkl\", \"wb\"), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.1M\ttfidf_categorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "!du -sh tfidf_categorizer.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open(\"clf_categorizer.pkl\", \"wb\"), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.1M\tclf_categorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "!du -sh clf_categorizer.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.816"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "# Test class\n",
    "from categorizer import Categorizer\n",
    "\n",
    "categorizer = Categorizer()\n",
    "pred = categorizer.pred(X_test)\n",
    "(pred == y_test).sum()/y_test.shape[0]"
   ]
  },
  {
   "source": [
    "Final accuracy is correct, loading and using model works fine."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}