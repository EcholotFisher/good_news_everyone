{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Sentiment label to the webhose dataset\n",
    "In this notebook we will add sentiments to ~7k articles from the webhose set. For this we will use 3 different dictionary-based sentiment analysers. NLTK, TextBlob and the StanfordNLP library.\n",
    "The Stanford Analysis is very slow and took nearly 14 hours to run over 7k articles, which is why we didn't use more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Set path for function import and import functions\n",
    "sys.path.append('../../Functions')\n",
    "\n",
    "from datasets import load_stratified_dataset # Loads from the webhose data in a balanced manner (equal distribution of categories)\n",
    "from stanford_sentiment import Sentiment_StanfordNLP # Self-written function in which the Stanford-Sentiment-Analysis is applied to text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data \n",
    "df_orig = load_stratified_dataset('../dataset_categories/dataset.csv', 'category' , 7000, random_seed=47)\n",
    "\n",
    "# Copy the dataframe\n",
    "df = df_orig.copy()\n",
    "\n",
    "# Drop unused columns\n",
    "df.drop(['organizations', 'locations', 'published', 'category', 'site', 'country', 'text_length'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK and TextBlob\n",
    "Both tokenize the input and score the full string as one entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis with TextBlob and NLTK\n",
    "\n",
    "# NLTK\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "df[['neg', 'neu', 'pos', 'Vader_Score']] = df['text'].apply(sid.polarity_scores).apply(pd.Series)\n",
    "df.drop(['neg', 'neu', 'pos'], axis=1, inplace=True) # We only want the overall score\n",
    "\n",
    "# TextBlob\n",
    "df[['TextBlob_Score', 'subjectivity']] = df['text'].apply(lambda x:TextBlob(x).sentiment).apply(pd.Series)\n",
    "df.drop('subjectivity', axis=1, inplace=True) # We only need the polarity score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StanfordNLP\n",
    "The Stanford sentiment analyser scores whole sentences, which means that for an article with n sentences it would return n scores.\n",
    "Since we only want a single score in the end, we simply use the mean of n scores as a final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis with StanfordNLP\n",
    "Stanford_Score = []\n",
    "for i in range(df.shape[0]):\n",
    "    print(i, end='\\r')\n",
    "    try:\n",
    "        Stanford_Score.append(Sentiment_StanfordNLP(df.text[i]))\n",
    "    except:\n",
    "        Stanford_Score.append(None)\n",
    "df['Stanford_Score'] = pd.DataFrame(Stanford_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataset\n",
    "df.to_csv('dataset_with_sentiment.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
