{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datacleaning\n",
    "Check data, make it usable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to append different categories\n",
    "l = []\n",
    "# Loop over all given csv in folder\n",
    "for file in glob('raw_data/*.csv'):\n",
    "    df = pd.read_csv(file)\n",
    "    # Get category, add column to dataframe\n",
    "    category = file.split('/')[-1].split(\"\\\\\")[-1].split('.')[0]\n",
    "    df['category'] = category\n",
    "    l.append(df)\n",
    "\n",
    "# Add all data frames together\n",
    "df = pd.concat(l, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sports           156899\n",
       "politics          87157\n",
       "world             60297\n",
       "entertainment     50282\n",
       "travel            49470\n",
       "financial         47851\n",
       "technology        41476\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out Columns\n",
    "Remove useless ones!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organizations uuid thread author url ord_in_thread title locations entities highlightText language persons text external_links published crawled highlightTitle category\n"
     ]
    }
   ],
   "source": [
    "print(*df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### organizations\n",
    "Could be useful for eda, __check later__!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.organizations.unique()\n",
    "df.drop('organizations', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### thread\n",
    "Find useful information in thread!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97132 entries could not be loaded!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# turn str to dict\n",
    "count=0\n",
    "l = []\n",
    "for s in df.thread.values:\n",
    "    s = s.replace(\"\\'\", '\\\"') # replace single quotes to double quotes because json does not support single quotes\n",
    "    try: # Try to load as json, some values are wrong\n",
    "        l.append(json.loads(s))\n",
    "    except:\n",
    "        l.append({'false': False})\n",
    "        count += 1\n",
    "print('{} entries could not be loaded!'.format(count))\n",
    "        \n",
    "df.thread = l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove__ entries that could not be converted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['false' not in i for i in  [i.keys() for i in df.thread.values]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['social', 'site_full', 'main_image', 'site_section', 'section_title', 'url', 'country', 'title', 'performance_score', 'site', 'participants_count', 'title_full', 'spam_score', 'site_type', 'published', 'replies_count', 'uuid'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.thread.values[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i['social']['pinterest']['shares'] for i in df.thread.values if 'social' in i.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Social seems to be __zero__ for __every value__!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'newsdump.com'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.thread.values[1]['site']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['site'] = [i['site'] for i in df.thread.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newsdump.com              71998\n",
       "wn.com                    20460\n",
       "yahoo.com                 15868\n",
       "cbs8.com                  10907\n",
       "reuters.com                8372\n",
       "                          ...  \n",
       "ipsnews.net                   1\n",
       "spacewar.com                  1\n",
       "capsta.co.uk                  1\n",
       "scientificamerican.com        1\n",
       "hindawi.com                   1\n",
       "Name: site, Length: 1868, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.site.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Website could be __useful__ for __eda__!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CZ'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.thread.values[1]['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'] = [i['country'] for i in df.thread.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    239304\n",
       "CZ     72003\n",
       "GB     34176\n",
       "AU     11576\n",
       "IL      9751\n",
       "        7817\n",
       "CA      4841\n",
       "IE      4495\n",
       "IN      2702\n",
       "SG      2129\n",
       "EU      2016\n",
       "CH       901\n",
       "JE       887\n",
       "EG       706\n",
       "MY       676\n",
       "IT       471\n",
       "ZA       417\n",
       "TH       327\n",
       "AE       267\n",
       "ID       211\n",
       "NZ       199\n",
       "FR       130\n",
       "HK        99\n",
       "JP        43\n",
       "CR        39\n",
       "PA        37\n",
       "DE        24\n",
       "GR        16\n",
       "TR        15\n",
       "VG        10\n",
       "VN         9\n",
       "RS         4\n",
       "RU         1\n",
       "BE         1\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.country.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Country__ is useful for eda, __include__ as new __column__!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([i['site_type'] for i in df.thread.values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Site type only has one value, so no need to use it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove__ feature __thread__ afterwards!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('thread', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### title\n",
    "Looks like it can be directly used like this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Healthiest Pastas: From Quinoa to Buckwheat Noodles'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n' ' ' \"'\" ',' '-' '.' '0' '1' '2' '4' ':' 'A' 'B' 'C' 'D' 'F' 'H' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'V' 'W' 'Y' '[' ']' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'k' 'l' 'm' 'n' 'o' 'p' 'r' 's' 't' 'u' 'v' 'w' 'y' '£' "
     ]
    }
   ],
   "source": [
    "for i in sorted(set(str(df.title.values))):\n",
    "    print(repr(i), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### locations\n",
    "Could be __useful__ for later __eda__!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.locations.values[1]\n",
    "df.drop('locations', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove tags at end of article\n",
    "df.text = [i.split('\\nTAGS')[0] for i in df.text.values]\n",
    "# Remove Copyright at end of article\n",
    "df.text = [i.split('\\nCopyright')[0] for i in df.text.values]\n",
    "# Remove Copyright as sign\n",
    "df.text = [i.split('\\n©')[0] for i in df.text.values]\n",
    "# Remove texts consisting only of *** *** ***\n",
    "df = df[[False if '*** ***' in text else True for text in df.text]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove texts with strange multiple '...' because only 10000 and we are too  lazy to do more analysis\n",
    "df['num_triple_dots'] = [len(i.split('...')) for i in df.text.values]\n",
    "df = df.query('num_triple_dots < 4')\n",
    "df.drop('num_triple_dots', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include feature text length\n",
    "df['text_length'] = [len(i) for i in df.text.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187982"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove texts that are too long or too small\n",
    "df = df.query('text_length > 800 & text_length < 5000')\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n' ' ' '\"' '$' '%' '&' \"'\" '(' ')' ',' '-' '.' '/' '0' '1' '2' '3' '4' '5' '6' '7' '8' '9' ':' ';' '?' 'A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'R' 'S' 'T' 'U' 'V' 'W' 'Y' 'Z' '[' '\\\\' ']' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z' '–' '—' '’' '“' '”' "
     ]
    }
   ],
   "source": [
    "for i in sorted(set(str(df.text.values))):\n",
    "    print(repr(i), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### published\n",
    "__Useful__ for __eda__ later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015-10-02T03:00:00.000+03:00'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.published.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unnecessary columns\n",
    "__Remove__ uuid, author, url, ord_in_thread, entities, highlightText, highlightTitle, language, persons, external_links, crawled.\\\n",
    "These columns have no use for our purpose!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = ['uuid', 'author', 'url', 'ord_in_thread', 'entities', 'highlightText', 'highlightTitle', 'language', 'persons', 'external_links', 'crawled']\n",
    "df.drop(to_remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sports           50592\n",
       "financial        30173\n",
       "world            27425\n",
       "travel           26266\n",
       "technology       20972\n",
       "entertainment    20028\n",
       "politics         12526\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### News data set ####\n",
      "# of observations: 187982\n",
      "# of features:          7\n"
     ]
    }
   ],
   "source": [
    "print('#### News data set ####')\n",
    "print('# of observations: {}'.format(df.shape[0]))\n",
    "print('# of features:          {}'.format(df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          4\n",
       "text           0\n",
       "published      0\n",
       "category       0\n",
       "site           0\n",
       "country        0\n",
       "text_length    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove__ nans, only 5!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Test set\n",
    "With xxx values per category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = 500\n",
    "# Split dataset, each category with same sample size\n",
    "TEST = []\n",
    "TRAIN = []\n",
    "for i in df.category.unique():\n",
    "    tmp = df[df['category'] == i]\n",
    "    train, test = train_test_split(tmp, shuffle=True, test_size=(xxx/(tmp.shape[0]+0.001)), random_state=42)\n",
    "    TEST.append(test)\n",
    "    TRAIN.append(train)\n",
    "df_test = pd.concat(TEST, axis=0, ignore_index=True)\n",
    "df = pd.concat(TRAIN, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "politics         500\n",
       "technology       500\n",
       "entertainment    500\n",
       "travel           500\n",
       "financial        500\n",
       "sports           500\n",
       "world            500\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train dataset\n",
    "Use about 20000 per category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xxx = df.category.value_counts(ascending=True)[0] # number of samples per category, take all if None\n",
    "xxx = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if xxx != None:\n",
    "    # Split dataset, each category with same sample size\n",
    "    l = []\n",
    "    for i in df.category.unique():\n",
    "        tmp = df[df['category'] == i]\n",
    "        test_size = (1-xxx/(tmp.shape[0]+0.001))\n",
    "        if test_size > 0:\n",
    "            tmp, _ = train_test_split(tmp, shuffle=True, test_size=test_size, random_state=42)\n",
    "        l.append(tmp)\n",
    "    df = pd.concat(l, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "world            19999\n",
       "sports           19999\n",
       "technology       19999\n",
       "financial        19999\n",
       "travel           19999\n",
       "entertainment    19528\n",
       "politics         12026\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished in 3986.39s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "# Add functions path\n",
    "import sys\n",
    "sys.path.append('../../Functions')\n",
    "from text_lemmatization import Lemmatizer\n",
    "lemmatizer = Lemmatizer()\n",
    "start = time()\n",
    "df['text_lem'] = lemmatizer.lem_list(df.text)\n",
    "df_test['text_lem'] = lemmatizer.lem_list(df_test.text)\n",
    "print('finished in {:.2f}s'.format(time()-start))\n",
    "# Took about 55 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes\n",
    "df.to_csv('dataset_categories_train.csv', index=False)\n",
    "df_test.to_csv('dataset_categories_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
