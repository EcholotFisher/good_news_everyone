{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we try to get the top posts from the Reddits about news. In addition, we also directly store the links to the respective news articles. At the end we try to get all news articles of the different publishers via the urls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from psaw import PushshiftAPI\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "#pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psaw\n",
      "  Downloading psaw-0.0.12-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: Click in c:\\users\\svenr\\anaconda3\\lib\\site-packages (from psaw) (7.1.2)\n",
      "Requirement already satisfied: requests in c:\\users\\svenr\\anaconda3\\lib\\site-packages (from psaw) (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\svenr\\anaconda3\\lib\\site-packages (from requests->psaw) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\svenr\\anaconda3\\lib\\site-packages (from requests->psaw) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\svenr\\anaconda3\\lib\\site-packages (from requests->psaw) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\svenr\\anaconda3\\lib\\site-packages (from requests->psaw) (1.25.9)\n",
      "Installing collected packages: psaw\n",
      "Successfully installed psaw-0.0.12\n"
     ]
    }
   ],
   "source": [
    "# Install of the PushshiftAPI\n",
    "#!pip install psaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login credentials for praw & Reddit API\n",
    "r = praw.Reddit(client_id='ddxZYbBilApY5A', client_secret='4rxjgOizdOJlhuyD781bi4tCqH8', user_agent='Henlo')\n",
    "api = PushshiftAPI(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following function we will get the top 1000 posts from a specific reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reddit_details(reddit_name): \n",
    "    top_posts = r.subreddit(reddit_name).top(limit=1000)\n",
    "    lst = []\n",
    "    title = []\n",
    "    for post in top_posts:\n",
    "        lst.append(post.url)\n",
    "        title.append(post.title)\n",
    "    df = pd.DataFrame({'title' : title, 'url' : lst})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use newspaper3k to fetch all articles from our dataframe with all urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import urllib.request, urllib.error\n",
    "\n",
    "# download and parse articles\n",
    "def get_articles(start,end,prefix): \n",
    "    good = 0\n",
    "    bad = 0\n",
    "\n",
    "    articles_txt_list = []\n",
    "\n",
    "    for link in link_list[start:end]:\n",
    "            print(\"{}\".format(df.shape[0]-good+bad),end=\"\\r\") \n",
    "            if link == \"None\": \n",
    "                articles_txt_list.append(\"None\")\n",
    "                bad += 1 \n",
    "\n",
    "            else: \n",
    "                try:\n",
    "                    #conn = urllib.request.urlopen(link)\n",
    "                    n_article = Article(url=link, fetch_images=False, request_timeout=10, number_threads=15)\n",
    "                    n_article.download()\n",
    "                    n_article.parse()\n",
    "                    articles_txt_list.append(n_article.text)\n",
    "                    good += 1\n",
    "                except: \n",
    "                    bad +=1\n",
    "                    articles_txt_list.append(\"None\")\n",
    "\n",
    "    articles_txt_df = pd.DataFrame({\"article_txt\": articles_txt_list}) \n",
    "    articles_txt_df_con = pd.concat([df[start:end].reset_index(drop=True), articles_txt_df], axis=1)\n",
    "    articles_txt_df_con.to_csv(\"reddit_news_data/{}_dataset_{}_{}.csv\".format(prefix,start,end), index=False)\n",
    "\n",
    "\n",
    "    print(\"# Articles:\", len(articles_txt_list))\n",
    "    print(\"# bad:\", bad)\n",
    "    print(\"# good:\", good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### r/UplifitingNews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Reddit only good news are shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_reddit_details('UpliftingNews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = df.url.tolist()\n",
    "len(link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Articles: 990\n",
      "# bad: 135\n",
      "# good: 855\n"
     ]
    }
   ],
   "source": [
    "get_articles(0,df.shape[0], \"uplifiting_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Man falsely imprisoned for 10 years, uses pris...</td>\n",
       "      <td>https://www.nbcnews.com/news/us-news/defendant...</td>\n",
       "      <td>Attorney Jarrett Adams recently helped overtur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First paralyzed human treated with stem cells ...</td>\n",
       "      <td>https://educateinspirechange.org/science-techn...</td>\n",
       "      <td>Imagine losing control of your car and waking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Over a Million People Sign Petition Calling Fo...</td>\n",
       "      <td>https://www.newsweek.com/kkk-petition-terroris...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hollywood Superstar Keanu Reeves Has Secretly ...</td>\n",
       "      <td>https://www.theepochtimes.com/hollywood-supers...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon tribe wins legal battle against oil com...</td>\n",
       "      <td>https://www.disclose.tv/amazon-tribe-wins-laws...</td>\n",
       "      <td>The Amazon Rainforest is well known across the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Man falsely imprisoned for 10 years, uses pris...   \n",
       "1  First paralyzed human treated with stem cells ...   \n",
       "2  Over a Million People Sign Petition Calling Fo...   \n",
       "3  Hollywood Superstar Keanu Reeves Has Secretly ...   \n",
       "4  Amazon tribe wins legal battle against oil com...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.nbcnews.com/news/us-news/defendant...   \n",
       "1  https://educateinspirechange.org/science-techn...   \n",
       "2  https://www.newsweek.com/kkk-petition-terroris...   \n",
       "3  https://www.theepochtimes.com/hollywood-supers...   \n",
       "4  https://www.disclose.tv/amazon-tribe-wins-laws...   \n",
       "\n",
       "                                                   0  \n",
       "0  Attorney Jarrett Adams recently helped overtur...  \n",
       "1  Imagine losing control of your car and waking ...  \n",
       "2                                               None  \n",
       "3                                               None  \n",
       "4  The Amazon Rainforest is well known across the...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uplifting_news = pd.read_csv(\"reddit_news_data/uplifitng_news_dataset_0_990.csv\")\n",
    "uplifting_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "uplifting_news.rename(columns={\"0\": \"article_txt\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(834, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop None & NaN -> appears if the scraping was not successful\n",
    "uplifting_news.dropna(inplace=True)\n",
    "uplifting_news = uplifting_news[uplifting_news[\"article_txt\"] != \"None\"]\n",
    "uplifting_news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>article_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Man falsely imprisoned for 10 years, uses pris...</td>\n",
       "      <td>https://www.nbcnews.com/news/us-news/defendant...</td>\n",
       "      <td>Attorney Jarrett Adams recently helped overtur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First paralyzed human treated with stem cells ...</td>\n",
       "      <td>https://educateinspirechange.org/science-techn...</td>\n",
       "      <td>Imagine losing control of your car and waking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon tribe wins legal battle against oil com...</td>\n",
       "      <td>https://www.disclose.tv/amazon-tribe-wins-laws...</td>\n",
       "      <td>The Amazon Rainforest is well known across the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>No children died in traffic accidents in Norwa...</td>\n",
       "      <td>https://www.nrk.no/trondelag/ingen-barn-dode-i...</td>\n",
       "      <td>I 1970 døde det 560 mennesker i den norske tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>President Trump signs animal cruelty bill into...</td>\n",
       "      <td>https://abcnews.go.com/amp/Politics/president-...</td>\n",
       "      <td>President Trump signs animal cruelty bill into...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Man falsely imprisoned for 10 years, uses pris...   \n",
       "1  First paralyzed human treated with stem cells ...   \n",
       "4  Amazon tribe wins legal battle against oil com...   \n",
       "6  No children died in traffic accidents in Norwa...   \n",
       "7  President Trump signs animal cruelty bill into...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.nbcnews.com/news/us-news/defendant...   \n",
       "1  https://educateinspirechange.org/science-techn...   \n",
       "4  https://www.disclose.tv/amazon-tribe-wins-laws...   \n",
       "6  https://www.nrk.no/trondelag/ingen-barn-dode-i...   \n",
       "7  https://abcnews.go.com/amp/Politics/president-...   \n",
       "\n",
       "                                         article_txt  \n",
       "0  Attorney Jarrett Adams recently helped overtur...  \n",
       "1  Imagine losing control of your car and waking ...  \n",
       "4  The Amazon Rainforest is well known across the...  \n",
       "6  I 1970 døde det 560 mennesker i den norske tra...  \n",
       "7  President Trump signs animal cruelty bill into...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uplifting_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one column with the source\n",
    "uplifting_news[\"source\"] = [\"UpliftingNews\" for i in range(uplifting_news.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one column with the label (0 = bad, 1 = good)\n",
    "uplifting_news[\"label\"] = [1 for i in range(uplifting_news.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe the new/cleaned dataframe as csv \n",
    "uplifting_news.to_csv(\"reddit_news_data/cleaned/reddit_upliftingnews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### r/Collapse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook only bad news are shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_reddit_details('collapse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_list = df.url.tolist()\n",
    "len(link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Articles: 998\n",
      "# bad: 26\n",
      "# good: 972\n"
     ]
    }
   ],
   "source": [
    "get_articles(0,df.shape[0],\"collapse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     https://www.reddit.com/r/collapse/comments/gv7...\n",
       "1     https://www.reddit.com/r/collapse/comments/h8f...\n",
       "2                   https://i.redd.it/nxc4kdfc1d251.jpg\n",
       "3                   https://i.redd.it/98fyhfza47841.jpg\n",
       "4                   https://i.redd.it/24nnkbjs69p41.png\n",
       "5                   https://i.redd.it/ahigharrhhm51.jpg\n",
       "6     https://preview.redd.it/pmdknot1c8t41.jpg?widt...\n",
       "7                   https://i.redd.it/5yppxpdkemd51.jpg\n",
       "8                   https://i.redd.it/oddkv702f6d51.jpg\n",
       "9                   https://i.redd.it/o02xf18i2h151.jpg\n",
       "10                  https://i.redd.it/psigl5fv7q351.jpg\n",
       "11                  https://i.redd.it/am5djw8rk7v51.jpg\n",
       "12                  https://i.redd.it/jwvg2u2sr6f51.png\n",
       "13                  https://i.redd.it/s3dipqaut2s51.jpg\n",
       "14                      https://i.imgur.com/8jPnfr2.jpg\n",
       "15                  https://i.redd.it/492db98qzlm51.jpg\n",
       "16    https://finance.yahoo.com/news/world-2-000-bil...\n",
       "17    https://preview.redd.it/qzt1mydo9lg51.jpg?widt...\n",
       "18    https://www.weforest.org/sites/default/files/s...\n",
       "19                      https://i.imgur.com/0cHspjp.jpg\n",
       "20                  https://i.redd.it/1ie48czmn4l51.jpg\n",
       "21                  https://i.redd.it/nui9fx619nn41.jpg\n",
       "22                  https://i.redd.it/tj5x85k9ydb51.jpg\n",
       "23                  https://i.redd.it/2wtt3w8pmvy31.png\n",
       "24                  https://i.redd.it/r5eaih52xrj51.png\n",
       "25                  https://i.redd.it/xhty3c0un4e41.jpg\n",
       "26                  https://i.redd.it/j6gn1722ts541.jpg\n",
       "27                      https://v.redd.it/rixf4tkh3p231\n",
       "28                        https://streamable.com/u2jzoo\n",
       "29    https://morningconsult.com/2020/09/28/adults-c...\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.url[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are many urls which are note useful. \n",
    "We will delete them manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>article_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The US is a Shithole Country</td>\n",
       "      <td>https://www.reddit.com/r/collapse/comments/gv7...</td>\n",
       "      <td>I’m so mad right now. I have so much loathing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a class war</td>\n",
       "      <td>https://www.reddit.com/r/collapse/comments/h8f...</td>\n",
       "      <td>Reposted again. Remember children, hug and kis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US Senator Tom Cotton calls for the military t...</td>\n",
       "      <td>https://i.redd.it/nxc4kdfc1d251.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Interesting Times</td>\n",
       "      <td>https://i.redd.it/98fyhfza47841.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Put into perspective</td>\n",
       "      <td>https://i.redd.it/24nnkbjs69p41.png</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                       The US is a Shithole Country   \n",
       "1                                This is a class war   \n",
       "2  US Senator Tom Cotton calls for the military t...   \n",
       "3                                  Interesting Times   \n",
       "4                               Put into perspective   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.reddit.com/r/collapse/comments/gv7...   \n",
       "1  https://www.reddit.com/r/collapse/comments/h8f...   \n",
       "2                https://i.redd.it/nxc4kdfc1d251.jpg   \n",
       "3                https://i.redd.it/98fyhfza47841.jpg   \n",
       "4                https://i.redd.it/24nnkbjs69p41.png   \n",
       "\n",
       "                                         article_txt  \n",
       "0  I’m so mad right now. I have so much loathing ...  \n",
       "1  Reposted again. Remember children, hug and kis...  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the csv file as dataframe\n",
    "collapse_news = pd.read_csv(\"reddit_news_data/collapse_dataset_0_998.csv\")\n",
    "collapse_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapse_news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop None & NaN -> appears if the scraping was not successful\n",
    "collapse_news.dropna(inplace=True)\n",
    "collapse_news = collapse_news[collapse_news[\"article_txt\"] != \"None\"]\n",
    "collapse_news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>article_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The US is a Shithole Country</td>\n",
       "      <td>https://www.reddit.com/r/collapse/comments/gv7...</td>\n",
       "      <td>I’m so mad right now. I have so much loathing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a class war</td>\n",
       "      <td>https://www.reddit.com/r/collapse/comments/h8f...</td>\n",
       "      <td>Reposted again. Remember children, hug and kis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The World’s 2,000 Billionaires Have More Wealt...</td>\n",
       "      <td>https://finance.yahoo.com/news/world-2-000-bil...</td>\n",
       "      <td>Wealth inequality is nothing new, but it’s rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>How humanity solves problems</td>\n",
       "      <td>https://v.redd.it/rixf4tkh3p231</td>\n",
       "      <td>Discussion regarding the potential collapse of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1 in 4 Childless Adults Say Climate Change Has...</td>\n",
       "      <td>https://morningconsult.com/2020/09/28/adults-c...</td>\n",
       "      <td>11% of childless adults say climate change is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                        The US is a Shithole Country   \n",
       "1                                 This is a class war   \n",
       "16  The World’s 2,000 Billionaires Have More Wealt...   \n",
       "27                       How humanity solves problems   \n",
       "29  1 in 4 Childless Adults Say Climate Change Has...   \n",
       "\n",
       "                                                  url  \\\n",
       "0   https://www.reddit.com/r/collapse/comments/gv7...   \n",
       "1   https://www.reddit.com/r/collapse/comments/h8f...   \n",
       "16  https://finance.yahoo.com/news/world-2-000-bil...   \n",
       "27                    https://v.redd.it/rixf4tkh3p231   \n",
       "29  https://morningconsult.com/2020/09/28/adults-c...   \n",
       "\n",
       "                                          article_txt  \n",
       "0   I’m so mad right now. I have so much loathing ...  \n",
       "1   Reposted again. Remember children, hug and kis...  \n",
       "16  Wealth inequality is nothing new, but it’s rea...  \n",
       "27  Discussion regarding the potential collapse of...  \n",
       "29  11% of childless adults say climate change is ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapse_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned before there a lot of stuff still in the dataframe which is not useful, i.e urls from reddit.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete the rows\n",
    "collapse_news = collapse_news[[True if 'jpg' not in i else False for i in collapse_news.url.values]]\n",
    "collapse_news = collapse_news[[True if 'youtu' not in i else False for i in collapse_news.url.values]]\n",
    "collapse_news = collapse_news[[True if 'png' not in i else False for i in collapse_news.url.values]]\n",
    "collapse_news = collapse_news[[True if 'amazon' not in i else False for i in collapse_news.url.values]]\n",
    "collapse_news = collapse_news[[True if 'twitter' not in i else False for i in collapse_news.url.values]]\n",
    "collapse_news = collapse_news[[True if '/r/' not in i else False for i in collapse_news.url.values]]\n",
    "collapse_news = collapse_news[[True if 'imgur' not in i else False for i in collapse_news.url.values]]\n",
    "collapse_news = collapse_news[[True if 'wikipedia' not in i else False for i in collapse_news.url.values]]\n",
    "collapse_news = collapse_news[[True if 'streamable' not in i else False for i in collapse_news.url.values]]\n",
    "collapse_news = collapse_news[[True if 'pulse' not in i else False for i in collapse_news.url.values]]\n",
    "collapse_news = collapse_news[[True if 'feralatlas' not in i else False for i in collapse_news.url.values]]\n",
    "collapse_news = collapse_news[[True if 'thesocialdilemma' not in i else False for i in collapse_news.url.values]]\n",
    "collapse_news = collapse_news[[True if 'collapsepod' not in i else False for i in collapse_news.url.values]]\n",
    "collapse_news = collapse_news[[True if 'kisstheground' not in i else False for i in collapse_news.url.values]]\n",
    "collapse_news = collapse_news[[True if 'redd' not in i else False for i in collapse_news.url.values]]\n",
    "collapse_news = collapse_news[[True if 'medium.com' not in i else False for i in collapse_news.url.values]]\n",
    "\n",
    "collapse_news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one column with the source\n",
    "collapse_news[\"source\"] = [\"CollapseNews\" for i in range(collapse_news.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one column with the label (0 = bad, 1 = good)\n",
    "collapse_news[\"label\"] = [0 for i in range(collapse_news.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe the new/cleaned dataframe as csv \n",
    "collapse_news.to_csv(\"reddit_news_data/cleaned/reddit_collapse.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### r/JustGoodNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_reddit_details('JustGoodNews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_list = df.url.tolist()\n",
    "len(link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6960\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\svenr\\Anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py:1213: UnknownTimezoneWarning: tzname EDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Articles: 1000\n",
      "# bad: 94\n",
      "# good: 906\n"
     ]
    }
   ],
   "source": [
    "get_articles(0,df.shape[0],\"JustGoodNews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>article_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FBI uncovered Russian bribery plot before Obam...</td>\n",
       "      <td>http://thehill.com/policy/national-security/35...</td>\n",
       "      <td>Before the Obama administration approved a con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Keese Love Everyone -- Find him and bring him ...</td>\n",
       "      <td>http://thegatewaypundit.com/2020/08/breaking-4...</td>\n",
       "      <td>The anonymous message board 4Chan has once aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Muslims hand out thousands of roses at London ...</td>\n",
       "      <td>http://www.standard.co.uk/news/london/muslims-...</td>\n",
       "      <td>ES News email The latest headlines in your inb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kendrick Ray Castillo, the 18-year-old who sac...</td>\n",
       "      <td>https://reuters.com/article/us-colorado-shooti...</td>\n",
       "      <td>(The story corrected source in paragraph 11 of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DNC staffer murdered, was the leak to wikileaks.</td>\n",
       "      <td>http://www.foxnews.com/politics/2017/05/16/sla...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  FBI uncovered Russian bribery plot before Obam...   \n",
       "1  Keese Love Everyone -- Find him and bring him ...   \n",
       "2  Muslims hand out thousands of roses at London ...   \n",
       "3  Kendrick Ray Castillo, the 18-year-old who sac...   \n",
       "4   DNC staffer murdered, was the leak to wikileaks.   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://thehill.com/policy/national-security/35...   \n",
       "1  http://thegatewaypundit.com/2020/08/breaking-4...   \n",
       "2  http://www.standard.co.uk/news/london/muslims-...   \n",
       "3  https://reuters.com/article/us-colorado-shooti...   \n",
       "4  http://www.foxnews.com/politics/2017/05/16/sla...   \n",
       "\n",
       "                                         article_txt  \n",
       "0  Before the Obama administration approved a con...  \n",
       "1  The anonymous message board 4Chan has once aga...  \n",
       "2  ES News email The latest headlines in your inb...  \n",
       "3  (The story corrected source in paragraph 11 of...  \n",
       "4                                               None  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the csv file as dataframe\n",
    "justgoodnews = pd.read_csv(\"reddit_news_data/justgoodnews_dataset_0_1000.csv\")\n",
    "justgoodnews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(893, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop None & NaN -> appears if the scraping was not successful\n",
    "justgoodnews.dropna(inplace=True)\n",
    "justgoodnews = justgoodnews[justgoodnews[\"article_txt\"] != \"None\"]\n",
    "justgoodnews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one column with the source\n",
    "justgoodnews[\"source\"] = [\"JustGoodNews\" for i in range(justgoodnews.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one column with the label (0 = bad, 1 = good)\n",
    "justgoodnews[\"label\"] = [1 for i in range(justgoodnews.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe the new/cleaned dataframe as csv \n",
    "justgoodnews.to_csv(\"reddit_news_data/cleaned/reddit_justgoodnews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### r/JustBadNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_reddit_details('JustBadNews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_list = df.url.tolist()\n",
    "len(link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Articles: 1000\n",
      "# bad: 94\n",
      "# good: 906\n"
     ]
    }
   ],
   "source": [
    "get_articles(0,df.shape[0],\"JustBadNews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the csv file as dataframe\n",
    "justbadnews = pd.read_csv(\"reddit_news_data/justbadnews_dataset_0_1000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(893, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop None & NaN -> appears if the scraping was not successful\n",
    "justbadnews.dropna(inplace=True)\n",
    "justbadnews = justbadnews[justbadnews[\"article_txt\"] != \"None\"]\n",
    "justbadnews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one column with the source\n",
    "justbadnews[\"source\"] = [\"JustBadNews\" for i in range(justbadnews.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one column with the label (0 = bad, 1 = good)\n",
    "justbadnews[\"label\"] = [0 for i in range(justbadnews.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe the new/cleaned dataframe as csv \n",
    "justbadnews.to_csv(\"reddit_news_data/cleaned/reddit_justbadnews.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
